# https://www.facebook.com/notes/775294156352065/

<img src="https://scontent-den4-1.xx.fbcdn.net/v/t31.18172-8/15419743_10103347287954901_2744013366467623932_o.jpg?_nc_cat=107&ccb=1-7&_nc_sid=abc084&_nc_ohc=wx9jkZsK8qMAX_o8KhB&_nc_ht=scontent-den4-1.xx&oh=00_AfAbHXVzk-pQCMK__nsrhY9cgW64NY_PpV1awmnQO94VpQ&oe=6418C306" alt="Jarvis Diagram"/>

For assistants like Jarvis to be able to control everything in homes for more people, we need more devices to be connected and the industry needs to develop common APIs and standards for the devices to talk to each other.

I can text anything to my Jarvis bot, and it will instantly be relayed to my Jarvis server and processed. 

One thing that surprised me about my communication with Jarvis is that when I have the choice of either speaking or texting, I text much more than I would have expected. Similarly, when Jarvis communicates with me, I'd much rather receive that over text message than voice. That's because voice can be disruptive and text gives you more control of when you want to look at it. This suggests that future AI products cannot be solely focused on voice and will need a private messaging interface as well. 

Even though I think text will be more important for communicating with AIs than people realize, I still think voice will play a very important role too. The most useful aspect of voice is that it's very fast. You don't need to take out your phone, open an app, and start typing -- you just speak.

it's surprising how frequently I want to communicate with Jarvis when I'm not home, so having the phone be the primary interface rather than a home device seems critical.

Speech recognition systems have improved recently, but no AI system is good enough to understand conversational speech just yet. Speech recognition relies on both listening to what you say and predicting what you will say next, so structured speech is still much easier to understand than unstructured conversation.

On a psychologic level, once you can speak to a system, you attribute more emotional depth to it than a computer you might interact with using text or a graphic interface.

Zuckerberg's Jarvis uses several artificial intelligence techniques, including natural language processing, speech recognition, face recognition, and reinforcement learning, written in Python, PHP and Objective C.

"I have always been optimistic about AI bots, but my experience with Jarvis has made me even more optimistic that we'll all communicate with bots like Jarvis in the future."



**The AI technology is just getting good enough for this to be the basis of a great product, and it will get much better in the next few years** At the same time, I think the best products like this will be ones you can bring with you anywhere and communicate with privately as well.

# https://github.com/facebookresearch/fastText

In the longer term, I'd like to explore teaching Jarvis how to learn new skills itself rather than me having to teach it how to perform specific tasks. If I spent another year on this challenge, I'd focus more on learning how learning works.

Finally, over time it would be interesting to find ways to make this available to the world. I considered open sourcing my code, but it's currently too tightly tied to my own home, appliances and network configuration. If I ever build a layer that abstracts more home automation functionality, I may release that. Or, of course, that could be a great foundation to build a new product.