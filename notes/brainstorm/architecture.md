
# https://arxiv.org/abs/2212.08073
Make a model that trains the other model. Make a model that train the model that trains the model. ðŸ˜³

We first need a Toolformer to understand and send API requests. Why don't we make an adversarial audio encoder that creates lots of different types of requests, asked in different ways, and feed than into our toolformer? You press play, and then this thing just gets super good at understanding requests. You might also be able to do RL with this...have this thing learn how to speak like a human, understand different ways of saying things, and execute them perfectly

Do we even need to transcribe something to text? Maybe directly audio into transformer?